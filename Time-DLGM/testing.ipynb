{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5651277a-4947-47fd-9584-bc2d650f3849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:  cuda\n",
      "1.12.0+cu116\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from parse_data import get_data, get_modified_values, get_binary_values, make_data_scalar\n",
    "import numpy as np\n",
    "import random\n",
    "from data_gen import Datagen\n",
    "from recognition import Recognition\n",
    "from generator import Generator\n",
    "from evaluation import evaluate_model, bin_plot\n",
    "from time_recognition import TimeRecognition\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#device=None\n",
    "print(\"Using device: \", device)\n",
    "\n",
    "import torch\n",
    "print(torch.__version__)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23f4c9a1-56ec-4e52-abf2-e0fd1eb372dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x tensor([[0.],\n",
      "        [0.]], device='cuda:0')\n",
      "y tensor([1.], device='cuda:0')\n",
      "x_1 tensor([[0.],\n",
      "        [1.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "gen = Datagen(device)\n",
    "\n",
    "x, y, x_1 = gen.get_generated_data(seq_len=2)\n",
    "\n",
    "print(\"x\", x[0])\n",
    "print(\"y\", y[0])\n",
    "print(\"x_1\", x_1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "871731c4-a079-4f95-a217-6583583456b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Hyperparameters\n",
    "sequence_length = [2*i for i in range(4,16)] # 2-20 increments of two\n",
    "hidden_layers = [1,2] # 1 and 2\n",
    "hidden_1 = [2**i for i in range(5,10)] # 2^4 to 2^9\n",
    "hidden_2 =[2**i for i in range(5,10)] # 2^2 to 2^5\n",
    "variance = [0.001, 0.01, 0.005, 0.05]\n",
    "lr = [0.001, 0.01, 0.1, 0.005] # stop at 0.005\n",
    "data_probability = [i/5 for i in range(1,6)]\n",
    "regularization = [1/i for i in range(1,10)]\n",
    "epochs = 1000\n",
    "optimizer = [optim.Adam, optim.SGD]\n",
    "\n",
    "options = []\n",
    "\n",
    "for seq_len in sequence_length:\n",
    "    for layers in hidden_layers:\n",
    "        for h1 in hidden_1:\n",
    "            for h2 in hidden_2:\n",
    "                for l in lr:\n",
    "                    for v in variance:\n",
    "                        for p in data_probability:\n",
    "                            for r in regularization:\n",
    "                                entry = {}\n",
    "                                entry[\"seq_len\"] = seq_len\n",
    "                                entry[\"layers\"] = layers\n",
    "                                entry[\"latent\"] = h1\n",
    "                                entry[\"hidden\"] = h2\n",
    "                                entry[\"l\"] = l\n",
    "                                entry[\"variance\"] = v\n",
    "                                entry[\"data_prob\"] = p\n",
    "                                entry[\"regularization\"] = r\n",
    "                                options.append(entry)\n",
    "                \n",
    "                                         \n",
    "random.shuffle(options)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffd60a9-84a0-4482-9024-852364a1635e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad534be-bb82-41da-87ff-929f023a02af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0.312077529670053, 477.56629952788353]\n",
      "[10, 0.30771043414235427, 471.42423102259636]\n",
      "[20, 0.3080624114362129, 472.54341384768486]\n",
      "[30, 0.3091093396704751, 473.4463768005371]\n",
      "[40, 0.31107459201747384, 478.76396971940994]\n",
      "[50, 0.31286777598739607, 478.1214468181133]\n",
      "[60, 0.3094706804766356, 472.9886225759983]\n",
      "[70, 0.30314495165494343, 464.2719032764435]\n",
      "[80, 0.29618958979066917, 453.87629717588425]\n",
      "[90, 0.29678521824723436, 454.33418518304825]\n",
      "[100, 0.29558701595344994, 453.04973059892654]\n",
      "[110, 0.29645705672452716, 454.5417075455189]\n",
      "[120, 0.296752140587366, 455.5197613835335]\n",
      "[130, 0.3013926429319008, 462.3980400264263]\n",
      "[140, 0.29772648991477085, 455.91347500681877]\n",
      "[150, 0.3000812692173779, 458.12842071056366]\n",
      "[160, 0.303511050425217, 464.7561329007149]\n",
      "[170, 0.3003164085683561, 460.46073055267334]\n",
      "[180, 0.3243905251198898, 492.9917862266302]\n",
      "[190, 0.2956479231464645, 452.7245151102543]\n",
      "[200, 6.468756413447133, 10189.418863475323]\n",
      "[210, 0.30277800419934425, 463.4628230035305]\n",
      "[220, 0.29760770760379324, 455.7158586680889]\n",
      "[230, 0.3112945183917063, 476.02167877554893]\n",
      "[240, 0.30756893815283054, 471.28544296324253]\n",
      "[250, 0.30235926019071596, 461.7388584911823]\n",
      "[260, 0.29568225832038386, 452.44318947196007]\n",
      "[270, 0.29378167683788753, 451.0913769900799]\n",
      "[280, 0.29219439736623365, 448.6314832866192]\n",
      "[290, 0.3032726665701007, 464.6710099577904]\n",
      "[300, 0.3019588269079323, 462.21251595020294]\n",
      "[310, 0.30002616867228526, 460.33258497714996]\n",
      "[320, 0.30220876566034693, 464.9808526337147]\n",
      "[330, 0.2960066000101772, 453.3317710161209]\n",
      "[340, 0.30477605626842996, 467.32479436695576]\n",
      "[350, 0.29820678935583206, 456.44329860806465]\n",
      "[360, 0.2998465353102659, 458.27172243595123]\n",
      "[370, 0.2926945657744109, 449.0160870850086]\n",
      "[380, 0.30252761498832825, 462.07932282984257]\n",
      "[390, 0.31601677418688884, 485.15971368551254]\n",
      "[400, 0.3139885624885248, 483.27178460359573]\n",
      "[410, 0.31029463913437594, 475.7668181359768]\n",
      "[420, 0.31440181162587655, 481.27348294854164]\n",
      "[430, 0.3159165944680377, 485.67974945902824]\n",
      "[440, 0.30770123576837793, 471.22919699549675]\n",
      "[450, 0.3098404513910296, 474.2459463775158]\n",
      "[460, 0.3562576379189292, 540.6526055261493]\n",
      "[470, 0.3086268724022584, 473.09142562747]\n",
      "[480, 0.3120210424221216, 478.07169157266617]\n",
      "[490, 0.30778407476667324, 472.1981648802757]\n",
      "[500, 0.3079837026468456, 471.7200335562229]\n",
      "[510, 0.30804856874379416, 471.86761224269867]\n",
      "[520, 0.30835208452401525, 473.07468953728676]\n",
      "[530, 0.31124025664970706, 475.99404072761536]\n",
      "[540, 0.3123363632485076, 477.4590455889702]\n",
      "[550, 0.3090491227941787, 473.20875614881516]\n",
      "[560, 0.3163141874747239, 483.02214100956917]\n",
      "[570, 0.326311717534501, 499.98407328128815]\n",
      "[580, 0.31971601885074735, 491.61792427301407]\n",
      "[590, 0.320637938014521, 491.76295429468155]\n",
      "[600, 0.31203379939181375, 478.0391773581505]\n",
      "[610, 0.32301670486015066, 492.952611297369]\n",
      "[620, 0.31783170356140433, 487.1846659183502]\n",
      "[630, 0.3108126325994808, 476.13089749217033]\n",
      "[640, 0.3147903700838201, 481.73903173208237]\n",
      "[650, 0.311293894721696, 477.3060131072998]\n",
      "[660, 0.3323390703288444, 508.76783686876297]\n",
      "[670, 0.31320629498432573, 479.6000771820545]\n",
      "[680, 0.3252745057910914, 496.5622765123844]\n",
      "[690, 0.3105281698408077, 476.52565136551857]\n",
      "[700, 0.31453330141757235, 484.265836507082]\n",
      "[710, 0.3126817896339663, 478.4994882643223]\n",
      "[720, 0.31423548249133887, 480.8642134666443]\n",
      "[730, 0.3070435010811056, 471.3111639022827]\n",
      "[740, 0.3127885617062877, 479.6011984050274]\n",
      "[750, 0.31088192702584727, 477.2146610021591]\n",
      "[760, 0.3134125290589295, 476.4578494131565]\n",
      "[770, 0.31198462958668916, 477.9973019361496]\n",
      "[780, 0.3132426819858912, 479.0938341319561]\n",
      "[790, 0.31795003387697685, 487.3310963511467]\n",
      "[800, 0.3123903377832694, 479.14464807510376]\n",
      "[810, 0.3089542444357673, 473.9168345928192]\n",
      "[820, 0.31831518659859354, 488.5342434346676]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import torch.utils.data as data\n",
    "from itertools import chain\n",
    "def loss(x, x_hat, mean, R, s, x_1,reg,  device=None, seq_len=1):\n",
    "\n",
    "    bce = nn.MSELoss( reduction='sum').to(device)\n",
    "    l = bce(x, x_hat)\n",
    "    amount = len(mean)\n",
    "    for m, r in zip(mean, R):\n",
    "        C = r @ r.transpose(-2,-1)\n",
    "        l += 0.5 * torch.sum(m.pow(2).sum(-1) \n",
    "                             + C.diagonal(dim1=-2,dim2=-1).sum(-1)\n",
    "                            - 2*C.diagonal(dim1=-2,dim2=-1).log().sum(-1) -1)\n",
    "\n",
    "    count = len(s)*2\n",
    "    for a, b in zip(s, x_1):\n",
    "        l += reg*bce(a[0], b[0])/count\n",
    "        l += reg*bce(a[1], b[1])/count\n",
    "    \n",
    "    return l \n",
    "\n",
    "best_model = None\n",
    "best_score = 10000000000000000\n",
    "batch_size = 10\n",
    "best_history= [0,0,0,0,0,0]\n",
    "for entry in options:\n",
    "\n",
    "    x_d, y_d, x_1_d = gen.get_generated_data(entry[\"seq_len\"], entry[\"variance\"], entry[\"data_prob\"])\n",
    "    x_t, y_t, x_t_1 = gen.get_true_data(entry[\"seq_len\"])\n",
    "    x_val, y_val, x_val_1 = gen.get_test_data(entry[\"seq_len\"])\n",
    "\n",
    "\n",
    "    model_t = TimeRecognition(input_dim=x_d[0].size()[1],\n",
    "                              hidden_size=entry[\"hidden\"],\n",
    "                              seq_len=entry[\"seq_len\"],\n",
    "                              layers=entry[\"layers\"],\n",
    "                             device=device)\n",
    "\n",
    "    model_g = Generator(hidden_size=entry[\"hidden\"],\n",
    "                        latent_dim=entry[\"latent\"],\n",
    "                        output_dim=y_d[0].size()[0],\n",
    "                        layers=entry[\"layers\"],\n",
    "                        seq_len=entry[\"seq_len\"],\n",
    "                        device=device)\n",
    "    model_r = Recognition(input_dim=x_d[0].size()[1],\n",
    "                          latent_dim=entry[\"latent\"],\n",
    "                          layers=entry[\"layers\"],\n",
    "                          device=device)\n",
    "\n",
    "    loader = data.DataLoader(data.TensorDataset(x_d, y_d, x_1_d), batch_size=batch_size, shuffle=True)\n",
    "    optimizer = optim.Adam(chain(model_r.parameters(), model_g.parameters(), model_t.parameters()), lr=0.01)\n",
    "    #optimizer = optim.Adam(model_r.parameters())\n",
    "    history = []\n",
    "    bce = nn.BCELoss().to(device)\n",
    "    for e in range(epochs):\n",
    "        model_g.train()\n",
    "        model_r.train()\n",
    "        model_t.train()\n",
    "\n",
    "\n",
    "        for x, y, x_1 in loader:\n",
    "\n",
    "            x.to(device)\n",
    "            y.to(device)\n",
    "            if x.size()[0] < batch_size:\n",
    "                continue\n",
    "            if random.random() < 0.5:\n",
    "                continue\n",
    "\n",
    "            t = model_t(x)\n",
    "            t_1 = model_t(x_1)\n",
    "            model_g.make_internal_state()\n",
    "            rec = model_r(x_1)\n",
    "            model_g.set_xi(rec[-1])\n",
    "            model_g.set_internal_state(t)\n",
    "            b, s = model_g()\n",
    "\n",
    "            l = loss(y, b, rec[0], rec[1], s, t_1, entry[\"regularization\"], device, entry[\"seq_len\"])\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "                        \n",
    "\n",
    "        \n",
    "        if e % 10 != 0:\n",
    "            continue\n",
    "        \n",
    "        count = 0\n",
    "        sum_loss = [0, 0]\n",
    "        for j in range(2):\n",
    "            for x, y, x_1 in loader:\n",
    "                model_g.eval()\n",
    "                model_t.eval()\n",
    "                model_r.eval()\n",
    "                model_g.make_internal_state()\n",
    "                model_g.make_xi()\n",
    "                with torch.no_grad():\n",
    "                    model_g.make_internal_state()\n",
    "                    rec = model_r(x_1)\n",
    "                    t = model_t(x)\n",
    "                    t_1 = model_t(x_1)\n",
    "                    model_g.set_internal_state(t)\n",
    "                    model_g.set_xi(rec[-1])\n",
    "                    b,s = model_g()\n",
    "                    l = loss(y, b, rec[0], rec[1],s,t_1,entry[\"regularization\"], device, entry[\"seq_len\"])\n",
    "                    res = []\n",
    "                    \n",
    "                    l = bce(b, y).cpu()\n",
    "                    sum_loss[j] += l.item()\n",
    "                    count += 1\n",
    "                    \n",
    "        \n",
    "        \n",
    "        sum_loss[0] /= count\n",
    "     \n",
    "        \n",
    "        history.append([e, sum_loss[0], sum_loss[1]])\n",
    "        print(history[-1])\n",
    "\n",
    "        if len(history) > 15:\n",
    "            #if no real improvements are being done stop the training. \n",
    "            # but keep doing the training if the results without correctly feeding values get better\n",
    "            if abs(history[-15][1] - history[-1][1]) < 0.0001:\n",
    "                break\n",
    "        \n",
    "    \n",
    "    if history[-1][1] < best_score:\n",
    "        print(\"New best model:\\nNew loss: \", history[-1], \"\\nOld loss:\", best_history[-1], \"\\nHistory:\" , history[-10:])\n",
    "        best_model = model_g\n",
    "        best_history = history\n",
    "        best_score = history[-1][1]\n",
    "        best_config = entry\n",
    "        with torch.no_grad():\n",
    "            evaluate_model(best_model,model_r, model_t, x_t, y_t, x_t_1,x_val,y_val, x_val_1, entry)\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            evaluate_model(model_g,model_r, model_t, x_t, y_t,x_val,y_val, x_val_1, entry)\n",
    "        print(\"Old model still stands:\\nCurrent loss: \", history[-1], \"\\nBest loss:\", best_history[-1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6fd679-0e46-4e3d-b548-b02dfed77de9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = torch.zeros(10,5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ffcb04-3b05-49bb-acab-3a092e164958",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[:,-1,:].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cb3216-ed30-4aef-b474-86876367c625",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.zeros(30,1)\n",
    "c = torch.zeros(1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dcd188-fc2a-4787-b7a8-37676fdfd0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cat((b[1:],c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0318994d-62c5-4561-8acc-bc76c62b377d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
