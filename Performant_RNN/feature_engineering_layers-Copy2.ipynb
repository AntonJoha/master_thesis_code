{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ecc6862-1f4c-4dbc-878a-28c97a990926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:  cuda\n"
     ]
    }
   ],
   "source": [
    "from parse_data import get_data, get_modified_values, get_binary_values, make_data_scalar\n",
    "from rnn_layers import PredictTime\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device: \", device)\n",
    "\n",
    "df = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31a932cf-5ecf-4c1f-9513-2400c8cb8686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1])\n",
      "Max value:  1000\n",
      "(tensor([[-1.0000],\n",
      "        [ 1.0000],\n",
      "        [ 0.4600],\n",
      "        ...,\n",
      "        [ 1.0000],\n",
      "        [ 0.4600],\n",
      "        [ 0.5900]], device='cuda:0'), tensor([[1.0000],\n",
      "        [0.4600],\n",
      "        [1.0000],\n",
      "        ...,\n",
      "        [0.4600],\n",
      "        [0.5900],\n",
      "        [0.5900]], device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def make_data(df, device):\n",
    "\n",
    "    x_train, y_train = [], []\n",
    "    prev = None\n",
    "\n",
    "    for row in df:\n",
    "        if prev is None:\n",
    "            prev = row\n",
    "        x_train.append(prev)\n",
    "        y_train.append(row)\n",
    "        prev = row\n",
    "    print(x_train[0].size())\n",
    "    return torch.stack(x_train).float().to(device),torch.stack(y_train).float().to(device)\n",
    "\n",
    "make_data(get_binary_values(get_data()), device)\n",
    "\n",
    "print(make_data_scalar(get_data(), device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f71633-04f1-488e-8421-3df5644a11a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max value:  1000\n",
      "torch.Size([8152, 1]) torch.Size([8152, 1])\n",
      "Epoch 0 Loss 29.8433\n",
      "Epoch 10 Loss 29.7095\n",
      "Epoch 20 Loss 29.6214\n",
      "Epoch 30 Loss 29.5551\n",
      "Epoch 40 Loss 29.2185\n",
      "Epoch 50 Loss 28.5259\n",
      "Epoch 60 Loss 28.4496\n",
      "Epoch 70 Loss 28.4447\n",
      "Epoch 80 Loss 28.4022\n",
      "Epoch 90 Loss 28.3774\n",
      "Epoch 100 Loss 28.3584\n",
      "Epoch 110 Loss 28.3727\n",
      "Epoch 120 Loss 28.3469\n",
      "Epoch 130 Loss 28.3149\n",
      "Epoch 140 Loss 28.3378\n",
      "Epoch 150 Loss 28.3100\n",
      "Epoch 160 Loss 28.3131\n",
      "Epoch 170 Loss 28.2708\n",
      "Epoch 180 Loss 28.2140\n",
      "Epoch 190 Loss 28.1580\n",
      "Epoch 200 Loss 28.1284\n",
      "Epoch 210 Loss 28.0243\n",
      "Epoch 220 Loss 27.9481\n",
      "Epoch 230 Loss 27.8191\n",
      "Epoch 240 Loss 27.5741\n",
      "Epoch 250 Loss 27.4800\n",
      "Epoch 260 Loss 27.2817\n",
      "Epoch 270 Loss 27.0101\n",
      "Epoch 280 Loss 26.4766\n",
      "Epoch 290 Loss 25.9748\n",
      "Epoch 300 Loss 26.2202\n",
      "Epoch 310 Loss 25.2728\n",
      "Epoch 320 Loss 24.4186\n",
      "Epoch 330 Loss 23.5503\n",
      "Epoch 340 Loss 22.9343\n",
      "Epoch 350 Loss 23.8585\n",
      "Epoch 360 Loss 22.3273\n",
      "Epoch 370 Loss 21.4727\n",
      "Epoch 380 Loss 20.6055\n",
      "Epoch 390 Loss 19.8990\n",
      "Epoch 400 Loss 19.8815\n",
      "Epoch 410 Loss 19.8275\n",
      "Epoch 420 Loss 19.5115\n",
      "Epoch 430 Loss 19.5387\n",
      "Epoch 440 Loss 18.8605\n",
      "Epoch 450 Loss 20.3210\n",
      "Epoch 460 Loss 18.8460\n",
      "Epoch 470 Loss 18.5445\n",
      "Epoch 480 Loss 18.0509\n",
      "Epoch 490 Loss 17.6446\n",
      "Epoch 500 Loss 17.5659\n",
      "Epoch 510 Loss 17.9001\n",
      "Epoch 520 Loss 17.8218\n",
      "Epoch 530 Loss 17.7642\n",
      "Epoch 540 Loss 17.4029\n",
      "Epoch 550 Loss 17.5586\n",
      "Epoch 560 Loss 17.3108\n",
      "Epoch 570 Loss 17.5352\n",
      "Epoch 580 Loss 17.2806\n",
      "Epoch 590 Loss 17.3722\n",
      "Epoch 600 Loss 17.2213\n",
      "Epoch 610 Loss 17.4194\n",
      "Epoch 620 Loss 17.4408\n",
      "Epoch 630 Loss 17.4087\n",
      "Epoch 640 Loss 17.2847\n",
      "Epoch 650 Loss 17.4038\n",
      "Epoch 660 Loss 17.3441\n",
      "Epoch 670 Loss 17.3670\n",
      "Epoch 680 Loss 17.3089\n",
      "Epoch 690 Loss 17.3950\n",
      "Epoch 700 Loss 17.4669\n",
      "Epoch 710 Loss 17.4090\n",
      "Epoch 720 Loss 17.2410\n",
      "Epoch 730 Loss 17.3133\n",
      "Epoch 740 Loss 17.3082\n",
      "Epoch 750 Loss 17.1311\n",
      "Epoch 760 Loss 17.2089\n",
      "Epoch 770 Loss 17.2185\n",
      "Epoch 780 Loss 17.2945\n",
      "Epoch 790 Loss 17.3519\n",
      "Epoch 800 Loss 17.1695\n",
      "Epoch 810 Loss 17.3180\n",
      "Epoch 820 Loss 17.1343\n",
      "Epoch 830 Loss 17.3612\n",
      "Epoch 840 Loss 17.4137\n",
      "Epoch 850 Loss 17.1504\n",
      "Epoch 860 Loss 17.2698\n",
      "Epoch 870 Loss 17.5682\n",
      "Epoch 880 Loss 17.2220\n",
      "Epoch 890 Loss 17.1253\n",
      "Epoch 900 Loss 17.2368\n",
      "Epoch 910 Loss 17.2344\n",
      "Epoch 920 Loss 17.3425\n",
      "Epoch 930 Loss 17.5352\n",
      "Epoch 940 Loss 17.5648\n",
      "Epoch 950 Loss 17.4597\n",
      "Epoch 960 Loss 17.2967\n",
      "Epoch 970 Loss 17.2975\n",
      "Epoch 980 Loss 17.3868\n",
      "Epoch 990 Loss 17.4253\n",
      "Epoch 1000 Loss 17.2537\n",
      "Epoch 1010 Loss 17.3034\n",
      "Epoch 1020 Loss 17.2409\n",
      "Epoch 1030 Loss 17.2928\n",
      "Epoch 1040 Loss 17.2531\n",
      "Epoch 1050 Loss 17.3972\n",
      "Epoch 1060 Loss 17.3108\n",
      "Epoch 1070 Loss 17.3819\n",
      "Epoch 1080 Loss 17.2800\n",
      "Epoch 1090 Loss 17.2815\n",
      "Epoch 1100 Loss 17.3334\n",
      "Epoch 1110 Loss 17.1745\n",
      "Epoch 1120 Loss 17.3527\n",
      "Epoch 1130 Loss 17.3230\n",
      "Epoch 1140 Loss 17.2545\n",
      "Epoch 1150 Loss 17.3879\n",
      "Epoch 1160 Loss 17.4194\n",
      "Epoch 1170 Loss 17.5784\n",
      "Epoch 1180 Loss 17.5420\n",
      "Epoch 1190 Loss 17.5250\n",
      "Epoch 1200 Loss 17.6222\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from IPython.display import clear_output\n",
    "import torch.nn as nn\n",
    "import random\n",
    "\n",
    "batch_size = 100\n",
    "x_d, y_d = make_data_scalar(get_data(), device)\n",
    "\n",
    "print(y_d.size(), x_d.size())\n",
    "\n",
    "model = PredictTime(input_size=x_d[0].size()[0],\n",
    "                    output_size=y_d[0].size()[0],\n",
    "                    hidden_layers=3,\n",
    "                    hidden_size=50, device=device).to(device)\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.01)\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "loader = data.DataLoader(data.TensorDataset(x_d,y_d), batch_size=batch_size)\n",
    "epochs = 5000\n",
    "for e in range(epochs):\n",
    "    model.train()\n",
    "    #print(next(iter(loader)))\n",
    "    model.clean_state()\n",
    "    res = []\n",
    "    \n",
    "    \n",
    "    #if random.random() < e/(epochs*2):\n",
    "        #model.teacher_forcing = False\n",
    "    #else:\n",
    "        #model.teacher_forcing = True\n",
    "    for x, y in loader:\n",
    "        \n",
    "        if random.random() < 0.5:\n",
    "            continue\n",
    "        model.random_state()\n",
    "        \n",
    "        \n",
    "        y_pred = model(x)\n",
    "        l = loss(y_pred, y)\n",
    "        res.append(l)\n",
    "        #print(y_pred, y)\n",
    "    \n",
    "    \n",
    "    l = res[0]\n",
    "    for i in res[1:]:\n",
    "        l += i\n",
    "    optimizer.zero_grad()\n",
    "    l.backward()\n",
    "    optimizer.step()\n",
    "    if e % 10 != 0:\n",
    "        continue\n",
    "    #clear_output(wait=True)\n",
    "    sum_loss = 0\n",
    "    #print(list(model.parameters())[-1])\n",
    "\n",
    "    for x, y in loader:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_pred = model(x)\n",
    "            sum_loss += np.sqrt(loss(y_pred, y).cpu())\n",
    "    \n",
    "    print(\"Epoch %d Loss %.4f\" % (e, sum_loss))\n",
    "    \n",
    "    \n",
    "#for d in df.values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76e66f0-9596-4127-b7c4-835709e375e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def eval_model(x,y,m):\n",
    "    df = get_data() \n",
    "    maxtime = df.max()[1]\n",
    "\n",
    "    res = []\n",
    "    m.eval()\n",
    "    m.clean_state()\n",
    "    count  = 1\n",
    "    prev = x[0][0]\n",
    "    for i in x:\n",
    "        t = torch.tensor([[prev]]).to(device)\n",
    "        prev = i\n",
    "        val = m(t)\n",
    "        count += 1\n",
    "        res.append(val.detach().cpu()[0])\n",
    "    \n",
    "    loss = nn.MSELoss()\n",
    "    print(np.sqrt(loss(torch.tensor(res).to(device),y.squeeze()).cpu()))\n",
    "    \n",
    "\n",
    "    fig, ax = plt.subplots(2)\n",
    "    \n",
    "    ax[0].plot(range(1,51), res[:50])\n",
    "    ax[0].plot( range(1,51), y[:50].cpu())\n",
    "\n",
    "    ax[1].plot(range(2000,2050), res[2000:2050])\n",
    "    \n",
    "    ax[1].plot(range(2000,2050), y[2000:2050].cpu() )\n",
    "    fig.suptitle(\"Result when feeding correct values as input\")\n",
    "    fig.savefig(\"teacher_forcing.png\")\n",
    "\n",
    "\n",
    "amount = 1000\n",
    "eval_model(x_d,y_d,model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2aa2663-d7c6-4407-8f5d-e8e3ab650e15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def eval_model(x,y,m):\n",
    "    df = get_data() \n",
    "    maxtime = df.max()[1]\n",
    "\n",
    "    res = []\n",
    "    m.eval()\n",
    "    m.clean_state()\n",
    "    count  = 1\n",
    "    prev = x[0][0]\n",
    "    for i in x:\n",
    "        t = torch.tensor([[prev]]).to(device)\n",
    "        prev = i\n",
    "        val = m(t)\n",
    "        prev = val\n",
    "        count += 1\n",
    "        res.append(val.detach().cpu()[0])\n",
    "    \n",
    "    loss = nn.MSELoss()\n",
    "    print(np.sqrt(loss(torch.tensor(res).to(device),y.squeeze()).cpu()))\n",
    "    \n",
    "    fig, ax = plt.subplots(2)\n",
    "    \n",
    "    ax[0].plot(range(1,51), res[:50])\n",
    "    ax[0].plot( range(1,51), y[:50].cpu())\n",
    "\n",
    "    ax[1].plot(range(2000,2050), res[2000:2050])\n",
    "    \n",
    "    ax[1].plot(range(2000,2050), y[2000:2050].cpu() )\n",
    "    fig.suptitle(\"Result without feeding correct values as input\")\n",
    "    fig.savefig(\"teacher_forcing_not_correct.png\")\n",
    "    \n",
    "amount = 1000\n",
    "eval_model(x_d,y_d,model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186992f6-b7a6-446e-9556-d36b32bb5bed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
