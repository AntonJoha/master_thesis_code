{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5651277a-4947-47fd-9584-bc2d650f3849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mauve-text in /opt/conda/lib/python3.10/site-packages (0.3.0)\n",
      "Requirement already satisfied: numpy>=1.18.1 in /opt/conda/lib/python3.10/site-packages (from mauve-text) (1.23.5)\n",
      "Requirement already satisfied: scikit-learn>=0.22.1 in /opt/conda/lib/python3.10/site-packages (from mauve-text) (1.2.2)\n",
      "Requirement already satisfied: faiss-cpu>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from mauve-text) (1.8.0)\n",
      "Requirement already satisfied: tqdm>=4.40.0 in /opt/conda/lib/python3.10/site-packages (from mauve-text) (4.65.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from mauve-text) (2.28.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.22.1->mauve-text) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.22.1->mauve-text) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.22.1->mauve-text) (3.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->mauve-text) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->mauve-text) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->mauve-text) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->mauve-text) (2023.11.17)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.39.3-py3-none-any.whl (8.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3 (from transformers)\n",
      "  Downloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m88.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m774.0/774.0 kB\u001b[0m \u001b[31m67.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.28.2)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers)\n",
      "  Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m80.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m80.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.65.0)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.19.3->transformers)\n",
      "  Downloading fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.0/172.0 kB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.11.17)\n",
      "Installing collected packages: safetensors, regex, fsspec, huggingface-hub, tokenizers, transformers\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.4.0\n",
      "    Uninstalling fsspec-2023.4.0:\n",
      "      Successfully uninstalled fsspec-2023.4.0\n",
      "Successfully installed fsspec-2024.3.1 huggingface-hub-0.22.2 regex-2023.12.25 safetensors-0.4.2 tokenizers-0.15.2 transformers-4.39.3\n",
      "Using device:  cuda\n",
      "1.12.0+cu116\n"
     ]
    }
   ],
   "source": [
    "!pip install mauve-text\n",
    "!pip install transformers\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from parse_data import get_data, get_modified_values, get_binary_values, make_data_scalar\n",
    "import numpy as np\n",
    "import random\n",
    "from data_gen import Datagen\n",
    "from recognition import Recognition\n",
    "from generator import Generator\n",
    "from evaluation import evaluate_model, bin_plot\n",
    "from time_recognition import TimeRecognition\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#device=None\n",
    "print(\"Using device: \", device)\n",
    "\n",
    "import torch\n",
    "print(torch.__version__)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23f4c9a1-56ec-4e52-abf2-e0fd1eb372dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x tensor([[0.],\n",
      "        [0.]], device='cuda:0')\n",
      "y tensor([1.], device='cuda:0')\n",
      "x_1 tensor([[0.],\n",
      "        [1.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "gen = Datagen(device)\n",
    "\n",
    "x, y, x_1 = gen.get_generated_data(seq_len=2)\n",
    "\n",
    "print(\"x\", x[0])\n",
    "print(\"y\", y[0])\n",
    "print(\"x_1\", x_1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "871731c4-a079-4f95-a217-6583583456b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Hyperparameters\n",
    "sequence_length = [2*i for i in range(4,16)] # 2-20 increments of two\n",
    "hidden_layers = [1,2] # 1 and 2\n",
    "hidden_1 = [2**i for i in range(2,7)] # 2^4 to 2^9\n",
    "hidden_2 =[2**i for i in range(5,10)] # 2^2 to 2^5\n",
    "variance = [0.001, 0.01, 0.005, 0.05]\n",
    "lr = [0.001, 0.01, 0.1, 0.005] # stop at 0.005\n",
    "data_probability = [i/5 for i in range(1,6)]\n",
    "regularization = [1/i for i in range(1,10)]\n",
    "for i in range(3):\n",
    "    regularization.append(0)\n",
    "\n",
    "epochs = 500\n",
    "optimizer = [optim.Adam, optim.SGD]\n",
    "\n",
    "options = []\n",
    "\n",
    "for seq_len in sequence_length:\n",
    "    for layers in hidden_layers:\n",
    "        for h1 in hidden_1:\n",
    "            for h2 in hidden_2:\n",
    "                for l in lr:\n",
    "                    for v in variance:\n",
    "                        for p in data_probability:\n",
    "                            for r in regularization:\n",
    "                                entry = {}\n",
    "                                entry[\"seq_len\"] = seq_len\n",
    "                                entry[\"layers\"] = layers\n",
    "                                entry[\"latent\"] = h1\n",
    "                                entry[\"hidden\"] = h2\n",
    "                                entry[\"l\"] = l\n",
    "                                entry[\"variance\"] = v\n",
    "                                entry[\"data_prob\"] = p\n",
    "                                entry[\"regularization\"] = r\n",
    "                                options.append(entry)\n",
    "                \n",
    "                                         \n",
    "random.shuffle(options)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffd60a9-84a0-4482-9024-852364a1635e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad534be-bb82-41da-87ff-929f023a02af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 55.342997319393305, 84166.4019241333]\n",
      "[10, 298.2315778607799, 461365.3545074463]\n",
      "[20, 183.71964498724077, 281458.49614715576]\n",
      "[30, 183.71964497479073, 281458.4960784912]\n",
      "[40, 183.7196449897308, 281458.49617767334]\n",
      "[50, 183.71964500467087, 281458.49609375]\n",
      "[60, 183.7196449922208, 281458.49618530273]\n",
      "[70, 183.71964507439117, 281458.4962463379]\n",
      "[80, 183.71964500467087, 281458.4961242676]\n",
      "[90, 183.7196450171209, 281458.49614715576]\n",
      "[100, 183.71964510925133, 281458.4961929321]\n",
      "[110, 183.71964497977075, 281458.49616241455]\n",
      "[120, 183.71964501961094, 281458.49616241455]\n",
      "[130, 183.71964502957098, 281458.4962615967]\n",
      "[140, 183.719645037041, 281458.4962310791]\n",
      "[150, 183.7196450569611, 281458.49628067017]\n",
      "[160, 183.71964505945112, 281458.4962081909]\n",
      "New best model:\n",
      "New loss:  [160, 183.71964505945112, 281458.4962081909] \n",
      "Old loss: 0 \n",
      "History: [[70, 183.71964507439117, 281458.4962463379], [80, 183.71964500467087, 281458.4961242676], [90, 183.7196450171209, 281458.49614715576], [100, 183.71964510925133, 281458.4961929321], [110, 183.71964497977075, 281458.49616241455], [120, 183.71964501961094, 281458.49616241455], [130, 183.71964502957098, 281458.4962615967], [140, 183.719645037041, 281458.4962310791], [150, 183.7196450569611, 281458.49628067017], [160, 183.71964505945112, 281458.4962081909]]\n",
      "Initial\n",
      "Initial_done\n",
      "HERE\n",
      "[500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "898d07744c964148afbe79d60ab0d944",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bc1f383d3224d94bf917c81a340bf9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/666 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "480340b077054f48b7f583d530ca53ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61afb78f53d44b998ded2d10fb61b619",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9a3da3ae7d54feca5ecc8050d9765f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41690f112c4c4749a1a08975fd31a4f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.25G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1cf7a34544d4344b6c36bc8c45b38a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Featurizing p:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89945d4175814939a979cca912ad94ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Featurizing q:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ae617a60a1245809b6ed36889e6f3a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Featurizing p:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "609a7eea3cd7477281ed73c17954e7a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Featurizing q:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 34.26416043015124, 52498.905822753906]\n",
      "[10, 33.94434952300149, 51979.42931365967]\n",
      "[20, 33.63369756952589, 51528.33807373047]\n",
      "[30, 33.75391267422908, 51710.025466918945]\n",
      "[40, 33.602752073004105, 51491.92070007324]\n",
      "[50, 34.650134865982416, 53080.588371276855]\n",
      "[60, 33.69112794144036, 51594.73513793945]\n",
      "[70, 33.642800079624585, 51545.92896270752]\n",
      "[80, 34.36446867163436, 52622.18698883057]\n",
      "[90, 33.65735165070616, 51564.32035827637]\n",
      "[100, 33.732890500101036, 51668.81099700928]\n",
      "[110, 34.24607987814721, 52459.55765533447]\n",
      "[120, 34.49877590547965, 52846.15427398682]\n",
      "[130, 36.25375480751456, 55570.26207733154]\n",
      "[140, 33.70114750774971, 51622.17028808594]\n",
      "[150, 34.40115761321145, 52714.83582305908]\n",
      "[160, 36.649600101202026, 56075.53936004639]\n",
      "[170, 33.578479871426175, 51430.02403259277]\n",
      "[180, 33.86613127207943, 51950.94662475586]\n",
      "[190, 34.226607623984236, 52509.40188598633]\n",
      "[200, 33.61651188026209, 51475.7967376709]\n",
      "[210, 34.8267305040484, 53321.865547180176]\n",
      "[220, 33.484098693409415, 51327.126220703125]\n",
      "[230, 34.489014941780745, 52682.57926940918]\n",
      "[240, 33.478997472060875, 51282.81874084473]\n",
      "[250, 33.992621499004315, 52058.805084228516]\n",
      "[260, 33.65069723004772, 51548.27048492432]\n",
      "[270, 33.92174916479046, 51994.16704559326]\n",
      "[280, 33.79746078511131, 51844.31505584717]\n",
      "[290, 33.51503084845082, 51354.17931365967]\n",
      "[300, 33.542806719986636, 51388.63293457031]\n",
      "[310, 36.43414483431425, 55696.39087677002]\n",
      "[320, 33.48716746297891, 51309.6448135376]\n",
      "[330, 36.360520674105416, 55509.156883239746]\n",
      "[340, 33.859085660690425, 51941.68039703369]\n",
      "[350, 33.91480938386046, 51998.7551651001]\n",
      "[360, 34.03987305344863, 52173.16905212402]\n",
      "[370, 34.843305025026005, 53339.151290893555]\n",
      "[380, 33.64590297728855, 51506.5654296875]\n",
      "[390, 33.577365571462764, 51432.11312866211]\n",
      "[400, 33.78874380345756, 51778.72876739502]\n",
      "[410, 33.88100942307913, 51951.95651245117]\n",
      "[420, 33.85237631038337, 51837.29633331299]\n",
      "[430, 35.81465517945451, 54850.57718658447]\n",
      "[440, 33.62734963439463, 51515.5862121582]\n",
      "[450, 34.77025444887325, 53265.11753845215]\n",
      "[460, 33.558304091968985, 51397.33060455322]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import torch.utils.data as data\n",
    "from itertools import chain\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def loss(x, x_hat, mean, R, s, x_1,reg,  device=None, seq_len=1):\n",
    "    \n",
    "    mse = nn.MSELoss().to(device)\n",
    "    l = F.binary_cross_entropy(x_hat, x, reduction='sum')\n",
    "    amount = mean[0].size()[0]*mean[0].size()[1]\n",
    "    for m, r in zip(mean, R):\n",
    "        \n",
    "        C = r @ r.transpose(-2,-1) + 1e-6\n",
    "        det = C.det() + 1e-6 \n",
    "        l += 0.5 * torch.sum(m.pow(2).sum(-1) \n",
    "                             + C.diagonal(dim1=-2,dim2=-1).sum(-1)\n",
    "                            -det.log()  -1)/amount\n",
    "\n",
    "    #count = len(s)*2\n",
    "    #for a, b in zip(s, x_1):\n",
    "    #    l += reg*mse(a[0], b[0])/count\n",
    "    #    l += reg*mse(a[1], b[1])/count\n",
    "    \n",
    "    #print(l, F.binary_cross_entropy(x_hat, x, reduction='sum'))\n",
    "    return l \n",
    "\n",
    "def loss_state(s, x_1,reg):\n",
    "    mse = nn.MSELoss().to(device)\n",
    "\n",
    "    count = len(s)*2\n",
    "    l = None\n",
    "    for a, b in zip(s, x_1):\n",
    "        if l is None:\n",
    "            l = reg*mse(a[0], b[0])/count\n",
    "        else:\n",
    "            l += reg*mse(a[0], b[0])/count\n",
    "        l += reg*mse(a[1], b[1])/count\n",
    "    \n",
    "    return l \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "best_model = None\n",
    "best_score = 10000000000000000\n",
    "batch_size = 10\n",
    "best_history= [0,0,0,0,0,0]\n",
    "for entry in options:\n",
    "\n",
    "    x_d, y_d, x_1_d = gen.get_generated_data(entry[\"seq_len\"], entry[\"variance\"], entry[\"data_prob\"])\n",
    "    x_t, y_t, x_t_1 = gen.get_true_data(entry[\"seq_len\"])\n",
    "    x_val, y_val, x_val_1 = gen.get_test_data(entry[\"seq_len\"])\n",
    "\n",
    "\n",
    "    model_t = TimeRecognition(input_dim=x_d[0].size()[1],\n",
    "                              hidden_size=entry[\"hidden\"],\n",
    "                              seq_len=entry[\"seq_len\"],\n",
    "                              layers=entry[\"layers\"],\n",
    "                             device=device)\n",
    "\n",
    "    model_g = Generator(hidden_size=entry[\"hidden\"],\n",
    "                        latent_dim=entry[\"latent\"],\n",
    "                        output_dim=y_d[0].size()[0],\n",
    "                        layers=entry[\"layers\"],\n",
    "                        seq_len=entry[\"seq_len\"],\n",
    "                        device=device)\n",
    "    model_r = Recognition(input_dim=x_d[0].size()[1],\n",
    "                          latent_dim=entry[\"latent\"],\n",
    "                          layers=entry[\"layers\"],\n",
    "                          device=device)\n",
    "\n",
    "    loader = data.DataLoader(data.TensorDataset(x_d, y_d, x_1_d), batch_size=batch_size, shuffle=True)\n",
    "    optimizer = optim.Adam(chain(model_r.parameters(), model_g.parameters(), model_t.parameters()), lr=entry[\"l\"])\n",
    "    #optimizer = optim.Adam(model_r.parameters())\n",
    "    history = []\n",
    "    bce = nn.BCELoss().to(device)\n",
    "    for e in range(epochs):\n",
    "        model_g.train()\n",
    "        model_r.train()\n",
    "        model_t.train()\n",
    "\n",
    "\n",
    "        for x, y, x_1 in loader:\n",
    "\n",
    "            x.to(device)\n",
    "            y.to(device)\n",
    "            if x.size()[0] < batch_size:\n",
    "                continue\n",
    "            if random.random() < 0.5:\n",
    "                continue\n",
    "\n",
    "            t = model_t(x)\n",
    "            t_1 = model_t(x_1)\n",
    "            model_g.make_internal_state()\n",
    "            rec = model_r(x_1)\n",
    "            model_g.set_xi(rec[-1])\n",
    "            model_g.set_internal_state(t)\n",
    "            b, s = model_g()\n",
    "\n",
    "            l = loss(y, b, rec[0], rec[1], s, t_1, entry[\"regularization\"], device, entry[\"seq_len\"])\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        for x, y , x_1 in loader:\n",
    "            x.to(device)\n",
    "            y.to(device)\n",
    "            if x.size()[0] < batch_size:\n",
    "                continue\n",
    "            if random.random() < 0.5:\n",
    "                continue\n",
    "            \n",
    "            t = model_t(x)\n",
    "            t_1 = model_t(x_1)\n",
    "            model_g.make_xi(batch_size)\n",
    "            model_g.set_internal_state(t)\n",
    "            _,s = model_g()\n",
    "            l = loss_state(s, t_1, entry[\"regularization\"])\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "                        \n",
    "\n",
    "        \n",
    "        if e % 10 != 0:\n",
    "            continue\n",
    "        \n",
    "        count = 0\n",
    "        sum_loss = [0, 0]\n",
    "        for j in range(2):\n",
    "            for x, y, x_1 in loader:\n",
    "                model_g.eval()\n",
    "                model_t.eval()\n",
    "                model_r.eval()\n",
    "                model_g.make_internal_state()\n",
    "                model_g.make_xi()\n",
    "                with torch.no_grad():\n",
    "                    model_g.make_internal_state()\n",
    "                    rec = model_r(x_1)\n",
    "                    t = model_t(x)\n",
    "                    t_1 = model_t(x_1)\n",
    "                    model_g.set_internal_state(t)\n",
    "                    model_g.set_xi(rec[-1])\n",
    "                    b,s = model_g()\n",
    "                    l = loss(y, b, rec[0], rec[1],s,t_1,entry[\"regularization\"], device, entry[\"seq_len\"])\n",
    "                    res = []\n",
    "                    \n",
    "                    sum_loss[j] += l.item()\n",
    "                    count += 1\n",
    "                    \n",
    "        \n",
    "        \n",
    "        sum_loss[0] /= count\n",
    "     \n",
    "        \n",
    "        history.append([e, sum_loss[0], sum_loss[1]])\n",
    "        print(history[-1])\n",
    "\n",
    "        if len(history) > 15:\n",
    "            #if no real improvements are being done stop the training. \n",
    "            # but keep doing the training if the results without correctly feeding values get better\n",
    "            if abs(history[-15][1] - history[-1][1]) < 0.0001:\n",
    "                break\n",
    "        \n",
    "    \n",
    "    if history[-1][1] < best_score:\n",
    "        print(\"New best model:\\nNew loss: \", history[-1], \"\\nOld loss:\", best_history[-1], \"\\nHistory:\" , history[-10:])\n",
    "        best_model = model_g\n",
    "        best_history = history\n",
    "        best_score = history[-1][1]\n",
    "        best_config = entry\n",
    "        with torch.no_grad():\n",
    "            evaluate_model(best_model,model_r, model_t, x_t, y_t, x_t_1,x_val,y_val, x_val_1, entry)\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            evaluate_model(model_g,model_r, model_t, x_t, y_t, x_t_1,x_val,y_val, x_val_1, entry)\n",
    "        print(\"Old model still stands:\\nCurrent loss: \", history[-1], \"\\nBest loss:\", best_history[-1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6fd679-0e46-4e3d-b548-b02dfed77de9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = torch.zeros(10,5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ffcb04-3b05-49bb-acab-3a092e164958",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[:,-1,:].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cb3216-ed30-4aef-b474-86876367c625",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.zeros(30,1)\n",
    "c = torch.zeros(1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dcd188-fc2a-4787-b7a8-37676fdfd0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cat((b[1:],c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0318994d-62c5-4561-8acc-bc76c62b377d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "23"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
